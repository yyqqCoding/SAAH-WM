"""
æµ‹è¯•ä¿å­˜çš„æ¨¡å‹æƒé‡
"""

import torch
import os
import glob
from models import FragileEncoder, RobustEncoder, RobustDecoder, FragileDecoder

def test_saved_models():
    """æµ‹è¯•ä¿å­˜çš„æ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•ä¿å­˜çš„æ¨¡å‹æƒé‡...")
    
    # æŸ¥æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹æ–‡ä»¶
    checkpoint_files = glob.glob("checkpoints/checkpoint_*.pth")
    if not checkpoint_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")
        return False
    
    # ä½¿ç”¨æœ€æ–°çš„æ£€æŸ¥ç‚¹
    latest_checkpoint = max(checkpoint_files, key=os.path.getctime)
    print(f"ğŸ“ åŠ è½½æ£€æŸ¥ç‚¹: {latest_checkpoint}")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(latest_checkpoint, map_location=device)
        print(f"âœ… æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ")
        print(f"  Epoch: {checkpoint['epoch']}")
        print(f"  Global Step: {checkpoint['global_step']}")
        
        # åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶çš„é…ç½®ï¼‰
        fragile_encoder = FragileEncoder(latent_channels=4, hidden_dim=32, num_layers=2).to(device)
        robust_encoder = RobustEncoder(latent_channels=4, message_dim=32, hidden_dim=32, num_layers=2).to(device)
        robust_decoder = RobustDecoder(latent_channels=4, message_dim=32, hidden_dim=32, num_layers=2).to(device)
        fragile_decoder = FragileDecoder(latent_channels=4, hidden_dim=32, num_layers=2).to(device)
        
        # åŠ è½½æƒé‡
        fragile_encoder.load_state_dict(checkpoint['fragile_encoder_state_dict'])
        robust_encoder.load_state_dict(checkpoint['robust_encoder_state_dict'])
        robust_decoder.load_state_dict(checkpoint['robust_decoder_state_dict'])
        fragile_decoder.load_state_dict(checkpoint['fragile_decoder_state_dict'])
        
        print("âœ… æ‰€æœ‰æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        fragile_encoder.eval()
        robust_encoder.eval()
        robust_decoder.eval()
        fragile_decoder.eval()
        
        # æµ‹è¯•æ¨ç†
        with torch.no_grad():
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            batch_size = 1
            height, width = 16, 16
            message_dim = 32
            
            image_latent = torch.randn(batch_size, 4, height, width).to(device)
            base_watermark = torch.randn(batch_size, 4, height, width).to(device)
            message_bits = torch.randint(0, 2, (batch_size, message_dim)).float().to(device)
            
            print("ğŸ”„ æ‰§è¡Œå®Œæ•´æ¨ç†æµç¨‹...")
            
            # æ­¥éª¤1: è„†å¼±æ°´å°åµŒå…¥
            watermarked_fragile = fragile_encoder(image_latent, base_watermark)
            print(f"  è„†å¼±åµŒå…¥: {image_latent.shape} -> {watermarked_fragile.shape}")
            
            # æ­¥éª¤2: é²æ£’ä¿¡æ¯åµŒå…¥
            watermarked_robust = robust_encoder(watermarked_fragile, message_bits)
            print(f"  é²æ£’åµŒå…¥: {watermarked_fragile.shape} -> {watermarked_robust.shape}")
            
            # æ­¥éª¤3: é²æ£’ä¿¡æ¯è§£ç 
            decoded_message = robust_decoder(watermarked_robust)
            print(f"  é²æ£’è§£ç : {watermarked_robust.shape} -> {decoded_message.shape}")
            
            # æ­¥éª¤4: è„†å¼±æ°´å°è§£ç 
            recovered_image, recovered_watermark = fragile_decoder(watermarked_robust)
            print(f"  è„†å¼±è§£ç : {watermarked_robust.shape} -> {recovered_image.shape}, {recovered_watermark.shape}")
            
            # è®¡ç®—ç®€å•æŒ‡æ ‡
            from utils.metrics import calculate_psnr, calculate_bit_accuracy
            
            psnr = calculate_psnr(watermarked_robust, image_latent)
            bit_accuracy = calculate_bit_accuracy(decoded_message, message_bits)
            
            print(f"ğŸ“Š æ¨ç†ç»“æœ:")
            print(f"  å›¾åƒPSNR: {psnr:.2f} dB")
            print(f"  æ¯”ç‰¹å‡†ç¡®ç‡: {bit_accuracy:.4f}")
            
            # ä¿å­˜å•ç‹¬çš„æ¨¡å‹æƒé‡æ–‡ä»¶
            models_dir = "trained_models"
            os.makedirs(models_dir, exist_ok=True)
            
            torch.save(fragile_encoder.state_dict(), os.path.join(models_dir, "fragile_encoder.pth"))
            torch.save(robust_encoder.state_dict(), os.path.join(models_dir, "robust_encoder.pth"))
            torch.save(robust_decoder.state_dict(), os.path.join(models_dir, "robust_decoder.pth"))
            torch.save(fragile_decoder.state_dict(), os.path.join(models_dir, "fragile_decoder.pth"))
            
            print(f"ğŸ’¾ æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ°: {models_dir}")
            for filename in ["fragile_encoder.pth", "robust_encoder.pth", "robust_decoder.pth", "fragile_decoder.pth"]:
                filepath = os.path.join(models_dir, filename)
                size_mb = os.path.getsize(filepath) / (1024 * 1024)
                print(f"  - {filename}: {size_mb:.1f} MB")
        
        print("âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_saved_models()
    if success:
        print("\nğŸ‰ æ¨¡å‹æƒé‡éªŒè¯æˆåŠŸï¼")
        print("âœ… è®­ç»ƒæµç¨‹å®Œæ•´å¯ç”¨")
        print("âœ… æ¨¡å‹æƒé‡ä¿å­˜æ­£å¸¸")
        print("âœ… æ¨ç†æµç¨‹è¿è¡Œæ­£å¸¸")
        print("âœ… å››ä¸ª.pthæ–‡ä»¶å·²ç”Ÿæˆ")
    else:
        print("\nâŒ æ¨¡å‹æƒé‡éªŒè¯å¤±è´¥")
