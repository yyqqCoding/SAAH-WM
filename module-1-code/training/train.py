"""
VQ-VAEè®­ç»ƒè„šæœ¬
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import argparse
import json
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.vqvae_model import SemanticVQVAE
from data.dataset import create_dataloaders
from training.config import get_default_config, get_small_config, get_large_config, save_config


class Trainer:
    """VQ-VAEè®­ç»ƒå™¨"""
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨

        è®¾ç½®æ¨¡å‹ã€æ•°æ®åŠ è½½å™¨ã€ä¼˜åŒ–å™¨ç­‰è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶
        """
        self.config = config
        self.device = torch.device(config.training.device)

        print("=" * 60)
        print("ğŸš€ åˆå§‹åŒ–SAAH-WMæ¨¡å—ä¸€è®­ç»ƒå™¨")
        print("=" * 60)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.training.output_dir, exist_ok=True)
        os.makedirs(os.path.join(config.training.output_dir, "logs"), exist_ok=True)

        # åˆ›å»ºæ¨¡å‹
        print("ğŸ“¦ åˆ›å»ºVQ-VAEæ¨¡å‹...")
        self.model = SemanticVQVAE(
            input_dim=config.model.input_dim,
            latent_dim=config.model.latent_dim,
            num_embeddings=config.model.num_embeddings,
            commitment_cost=config.model.commitment_cost,
            decay=config.model.decay,
            dropout=config.model.dropout
        ).to(self.device)

        model_params = sum(p.numel() for p in self.model.parameters())
        print(f"   âœ“ æ¨¡å‹å‚æ•°æ•°é‡: {model_params:,}")
        print(f"   âœ“ è¾“å…¥ç»´åº¦: {config.model.input_dim}")
        print(f"   âœ“ æ½œåœ¨ç»´åº¦: {config.model.latent_dim}")
        print(f"   âœ“ ç æœ¬å¤§å°: {config.model.num_embeddings}")
        print(f"   âœ“ å‹ç¼©æ¯”ç‰¹æ•°: {(config.model.num_embeddings - 1).bit_length()}")

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        try:
            self.train_loader, self.val_loader = create_dataloaders(
                train_vectors_path=config.training.train_vectors_path,
                val_vectors_path=config.training.val_vectors_path,
                batch_size=config.training.batch_size,
                num_workers=config.training.num_workers,
                pin_memory=config.training.pin_memory,
                noise_std=config.training.noise_std
            )
            print(f"   âœ“ è®­ç»ƒæ ·æœ¬æ•°: {len(self.train_loader.dataset):,}")
            print(f"   âœ“ éªŒè¯æ ·æœ¬æ•°: {len(self.val_loader.dataset):,}")
            print(f"   âœ“ æ‰¹å¤„ç†å¤§å°: {config.training.batch_size}")
            print(f"   âœ“ è®­ç»ƒæ‰¹æ¬¡æ•°: {len(self.train_loader)}")
        except Exception as e:
            print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print("   ğŸ’¡ è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬")
            raise

        # åˆ›å»ºä¼˜åŒ–å™¨
        print("âš™ï¸ åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨...")
        self.optimizer = self._create_optimizer()
        self.scheduler = self._create_scheduler()
        print(f"   âœ“ ä¼˜åŒ–å™¨: {config.training.optimizer}")
        print(f"   âœ“ å­¦ä¹ ç‡: {config.training.learning_rate}")
        print(f"   âœ“ æƒé‡è¡°å‡: {config.training.weight_decay}")

        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = GradScaler() if config.training.mixed_precision else None
        if config.training.mixed_precision:
            print("   âœ“ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")

        # æ—¥å¿—è®°å½•
        self.writer = SummaryWriter(log_dir=os.path.join(config.training.output_dir, "logs"))
        print(f"   âœ“ TensorBoardæ—¥å¿—: {os.path.join(config.training.output_dir, 'logs')}")

        # è®­ç»ƒçŠ¶æ€
        self.global_step = 0
        self.epoch = 0
        self.best_val_loss = float('inf')
        self.patience_counter = 0

        print(f"ğŸ–¥ï¸ è®­ç»ƒè®¾å¤‡: {self.device}")
        if self.device.type == 'cuda':
            print(f"   âœ“ GPUå‹å·: {torch.cuda.get_device_name()}")
            print(f"   âœ“ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

        print("=" * 60)
    
    def _create_optimizer(self):
        """åˆ›å»ºä¼˜åŒ–å™¨"""
        if self.config.training.optimizer.lower() == "adamw":
            return optim.AdamW(
                self.model.parameters(),
                lr=self.config.training.learning_rate,
                weight_decay=self.config.training.weight_decay
            )
        elif self.config.training.optimizer.lower() == "adam":
            return optim.Adam(
                self.model.parameters(),
                lr=self.config.training.learning_rate,
                weight_decay=self.config.training.weight_decay
            )
        else:
            raise ValueError(f"Unsupported optimizer: {self.config.training.optimizer}")
    
    def _create_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        if self.config.training.scheduler.lower() == "cosine":
            return optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.config.training.num_epochs
            )
        elif self.config.training.scheduler.lower() == "step":
            return optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.config.training.num_epochs // 3,
                gamma=0.1
            )
        else:
            return None
    
    def train_epoch(self):
        """
        è®­ç»ƒä¸€ä¸ªepoch

        æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒå¾ªç¯ï¼ŒåŒ…æ‹¬å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€å‚æ•°æ›´æ–°
        ä»¥åŠå®šæœŸçš„éªŒè¯å’Œæ£€æŸ¥ç‚¹ä¿å­˜
        """
        self.model.train()
        total_loss = 0
        total_recon_loss = 0
        total_vq_loss = 0

        # åˆ›å»ºè¿›åº¦æ¡ï¼Œæ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œå…³é”®æŒ‡æ ‡
        pbar = tqdm(self.train_loader, desc=f"ğŸ”„ Epoch {self.epoch + 1}/{self.config.training.num_epochs}")

        epoch_start_time = time.time()

        for batch_idx, batch in enumerate(pbar):
            batch = batch.to(self.device, non_blocking=True)

            self.optimizer.zero_grad()

            # å‰å‘ä¼ æ’­ - æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ
            if self.scaler:
                with autocast():
                    outputs = self.model(batch)
                    loss = outputs['total_loss']

                # åå‘ä¼ æ’­ - æ··åˆç²¾åº¦
                self.scaler.scale(loss).backward()

                # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
                if hasattr(self.config.training, 'max_grad_norm'):
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.training.max_grad_norm)

                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                outputs = self.model(batch)
                loss = outputs['total_loss']

                # åå‘ä¼ æ’­ - æ ‡å‡†ç²¾åº¦
                loss.backward()

                # æ¢¯åº¦è£å‰ª
                if hasattr(self.config.training, 'max_grad_norm'):
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.training.max_grad_norm)

                self.optimizer.step()

            # ç´¯è®¡æŸå¤±ç»Ÿè®¡
            total_loss += loss.item()
            total_recon_loss += outputs['recon_loss'].item()
            total_vq_loss += outputs['vq_loss'].item()

            # è·å–ç æœ¬åˆ©ç”¨ç‡
            codebook_util = self.model.get_codebook_utilization()

            # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
            pbar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'recon': f"{outputs['recon_loss'].item():.4f}",
                'vq': f"{outputs['vq_loss'].item():.4f}",
                'util': f"{codebook_util:.3f}",
                'lr': f"{self.optimizer.param_groups[0]['lr']:.2e}"
            })

            # è®°å½•è®­ç»ƒæ—¥å¿—åˆ°TensorBoard
            if self.global_step % self.config.training.log_interval == 0:
                self.writer.add_scalar('train/total_loss', loss.item(), self.global_step)
                self.writer.add_scalar('train/recon_loss', outputs['recon_loss'].item(), self.global_step)
                self.writer.add_scalar('train/vq_loss', outputs['vq_loss'].item(), self.global_step)
                self.writer.add_scalar('train/codebook_utilization', codebook_util, self.global_step)
                self.writer.add_scalar('train/learning_rate', self.optimizer.param_groups[0]['lr'], self.global_step)

                # è¯¦ç»†æ—¥å¿—è¾“å‡º
                if self.global_step % (self.config.training.log_interval * 10) == 0:
                    print(f"\nğŸ“Š Step {self.global_step} è¯¦ç»†ç»Ÿè®¡:")
                    print(f"   â€¢ æ€»æŸå¤±: {loss.item():.6f}")
                    print(f"   â€¢ é‡æ„æŸå¤±: {outputs['recon_loss'].item():.6f}")
                    print(f"   â€¢ VQæŸå¤±: {outputs['vq_loss'].item():.6f}")
                    print(f"   â€¢ ç æœ¬åˆ©ç”¨ç‡: {codebook_util:.3f}")
                    print(f"   â€¢ å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.2e}")

            # å®šæœŸéªŒè¯
            if self.global_step % self.config.training.val_interval == 0 and self.global_step > 0:
                print(f"\nğŸ” æ‰§è¡ŒéªŒè¯ (Step {self.global_step})...")
                val_loss = self.validate()
                self.writer.add_scalar('val/total_loss', val_loss, self.global_step)

                print(f"   éªŒè¯æŸå¤±: {val_loss:.6f}")

                # æ—©åœæ£€æŸ¥
                if val_loss < self.best_val_loss - self.config.training.early_stopping_min_delta:
                    improvement = self.best_val_loss - val_loss
                    self.best_val_loss = val_loss
                    self.patience_counter = 0
                    self.save_checkpoint(is_best=True)
                    print(f"   ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯æŸå¤±! æ”¹è¿›: {improvement:.6f}")
                else:
                    self.patience_counter += 1
                    print(f"   â³ éªŒè¯æŸå¤±æœªæ”¹è¿›ï¼Œè€å¿ƒè®¡æ•°: {self.patience_counter}/{self.config.training.early_stopping_patience}")

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if self.global_step % self.config.training.save_interval == 0 and self.global_step > 0:
                print(f"\nğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹ (Step {self.global_step})...")
                self.save_checkpoint()

            self.global_step += 1

        # è®¡ç®—epochå¹³å‡æŸå¤±
        avg_loss = total_loss / len(self.train_loader)
        avg_recon_loss = total_recon_loss / len(self.train_loader)
        avg_vq_loss = total_vq_loss / len(self.train_loader)

        epoch_time = time.time() - epoch_start_time

        print(f"\nğŸ“ˆ Epoch {self.epoch + 1} å®Œæˆ:")
        print(f"   â€¢ å¹³å‡æ€»æŸå¤±: {avg_loss:.6f}")
        print(f"   â€¢ å¹³å‡é‡æ„æŸå¤±: {avg_recon_loss:.6f}")
        print(f"   â€¢ å¹³å‡VQæŸå¤±: {avg_vq_loss:.6f}")
        print(f"   â€¢ è®­ç»ƒæ—¶é—´: {epoch_time:.1f}ç§’")
        print(f"   â€¢ ç æœ¬åˆ©ç”¨ç‡: {self.model.get_codebook_utilization():.3f}")

        return avg_loss, avg_recon_loss, avg_vq_loss
    
    def validate(self):
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        
        with torch.no_grad():
            for batch in self.val_loader:
                batch = batch.to(self.device)
                outputs = self.model(batch)
                total_loss += outputs['total_loss'].item()
        
        avg_loss = total_loss / len(self.val_loader)
        self.model.train()
        return avg_loss
    
    def save_checkpoint(self, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }
        
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(self.config.training.output_dir, 'latest_checkpoint.pt')
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹
        if is_best:
            best_path = os.path.join(self.config.training.output_dir, 'best_checkpoint.pt')
            torch.save(checkpoint, best_path)
            print(f"Saved best checkpoint with val_loss: {self.best_val_loss:.4f}")
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("Starting training...")
        start_time = time.time()
        
        for epoch in range(self.config.training.num_epochs):
            self.epoch = epoch
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss, recon_loss, vq_loss = self.train_epoch()
            
            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler:
                self.scheduler.step()
            
            # éªŒè¯
            val_loss = self.validate()
            
            print(f"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, "
                  f"recon_loss={recon_loss:.4f}, vq_loss={vq_loss:.4f}")
            
            # æ—©åœæ£€æŸ¥
            if self.patience_counter >= self.config.training.early_stopping_patience:
                print(f"Early stopping at epoch {epoch}")
                break
        
        total_time = time.time() - start_time
        print(f"Training completed in {total_time:.2f} seconds")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_path = os.path.join(self.config.training.output_dir, 'final_model.pt')
        torch.save(self.model.state_dict(), final_path)
        print(f"Final model saved to {final_path}")


def main():
    parser = argparse.ArgumentParser(description="Train Semantic VQ-VAE")
    parser.add_argument("--config", choices=["default", "small", "large"], default="default")
    parser.add_argument("--data_dir", default="./data/processed")
    parser.add_argument("--output_dir", default="./outputs")
    parser.add_argument("--device", default="cuda")
    parser.add_argument("--resume", type=str, help="Resume from checkpoint")
    
    args = parser.parse_args()
    
    # è·å–é…ç½®
    if args.config == "small":
        config = get_small_config()
    elif args.config == "large":
        config = get_large_config()
    else:
        config = get_default_config()
    
    # æ›´æ–°é…ç½®
    config.training.data_dir = args.data_dir
    config.training.output_dir = args.output_dir
    config.training.device = args.device
    config.training.resume_from_checkpoint = args.resume
    
    # æ£€æŸ¥è®¾å¤‡
    if args.device == "cuda" and not torch.cuda.is_available():
        print("CUDA not available, using CPU")
        config.training.device = "cpu"
    
    # ä¿å­˜é…ç½®
    save_config(config, os.path.join(config.training.output_dir, "config.json"))
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = Trainer(config)
    trainer.train()


if __name__ == "__main__":
    main()
